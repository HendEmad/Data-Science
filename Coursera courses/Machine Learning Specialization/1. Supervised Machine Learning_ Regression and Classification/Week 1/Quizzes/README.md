# Practice quiz: Regression
- For linear regression, the model is f_{w,b}(x) = wx + b

Which of the following are the inputs, or features, that are fed into the model and with which the model is expected to make a prediction?

```x```

- For linear regression, if you find parameters ww and bb so that J(w,b)J(w,b) is very close to zero, what can you conclude?

```The selected values of the parameters ww and bb cause the algorithm to fit the training set really well.```

# Practice quiz: Train the model with gradient descent

- Gradient descent is an algorithm for finding values of parameters w and b that minimize the cost function J. 

![image](https://user-images.githubusercontent.com/91827137/186957752-608867ea-3b75-480b-adf9-1fa7181444a4.png)

When (dj(w, b) / dw) is a negative number (less than zero), what happens to ww after one update step?

`w increases.`

- For linear regression, what is the update step for parameter b?

![image](https://user-images.githubusercontent.com/91827137/186958209-d4d4a93f-cf5c-4ce0-872d-029ce75611b8.png)
